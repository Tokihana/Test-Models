{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764f9584-d398-45bb-b797-39982244f8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7f5f02d-cbac-48db-9be9-af526d5d64d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117648"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "img = Image.open('./test.jpg')\n",
    "model_transform = v2.Compose([\n",
    "        v2.Resize(224),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "visual_transform = v2.Compose([\n",
    "        v2.Resize(7),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "    ])\n",
    "input_tensor = model_transform(img)\n",
    "input_tensor = input_tensor.unsqueeze(0)# Create an input tensor image for your model..\n",
    "rgb_img = visual_transform(img).permute(1, 2, 0).numpy()\n",
    "rgb_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9237f7ff-4864-48f5-93d9-7c4d6e42f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.cls_with_14 import CLSFER\n",
    "import timm\n",
    "#model = CLSFER()\n",
    "model = timm.create_model('vit_tiny_patch16_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d893ce4-44c7-4acc-b77f-4844e3902061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=192, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495ce9c1-fb46-4441-b67f-d267b733b1b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#target_layers = [model.layer4[-1]]\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m target_layers \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnorm1]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Note: input_tensor can be a batch tensor with several images!\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Construct the CAM object once, and then re-use it on many images:\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cam \u001b[38;5;241m=\u001b[39m GradCAM(model\u001b[38;5;241m=\u001b[39mmodel, target_layers\u001b[38;5;241m=\u001b[39mtarget_layers)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#target_layers = [model.layer4[-1]]\n",
    "target_layers = [model.blocks[-1].norm1]\n",
    "\n",
    "# Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "# You can also use it within a with statement, to make sure it is freed,\n",
    "# In case you need to re-create it inside an outer loop:\n",
    "# with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "#   ...\n",
    "\n",
    "# We have to specify the target we want to generate\n",
    "# the Class Activation Maps for.\n",
    "# If targets is None, the highest scoring category\n",
    "# will be used for every image in the batch.\n",
    "# Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
    "# That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
    "\n",
    "#targets = [ClassifierOutputTarget(256)]\n",
    "\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "#grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = cam(input_tensor=input_tensor)\n",
    "\n",
    "# In this example grayscale_cam has only one image in the batch:\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "# You can also get the model outputs without having to re-inference\n",
    "#model_outputs = cam.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5137512c-808e-4cae-b5c9-d8a002ccf49a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mvisualization\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'visualization' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774eae29-6f18-4185-97a6-f767b042f8c5",
   "metadata": {},
   "source": [
    "# plot confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab6106b-5225-4d4e-9cb0-ef1a97ea3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87038ca4-2a0f-4d63-bfcf-95d26fe2db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.rand((1000, 8)).argmax(dim=1)\n",
    "output = torch.rand((1000, 8)).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479bdaaa-df99-4043-86e3-ffc18d3b86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(i) for i in range(8)]\n",
    "label_map = ['anger', 'contempt', 'disgust', 'fear', 'happy', 'netural', 'sadness', 'surprise']\n",
    "cm = confusion_matrix(target.numpy(), output.numpy(), labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524199ff-ab84-4982-b808-14a2ac3d2187",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_predictions() got an unexpected keyword argument 'set_ticks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m disp \u001b[38;5;241m=\u001b[39m \u001b[43mConfusionMatrixDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mvalues_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.2\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mxticks_rotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisplay_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mset_ticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: from_predictions() got an unexpected keyword argument 'set_ticks'"
     ]
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay.from_predictions(target, output, \n",
    "                                               normalize='true',\n",
    "                                               values_format='.2%',\n",
    "                                               xticks_rotation=30, \n",
    "                                               display_labels=label_map,\n",
    "                                               cmap='Blues',)\n",
    "plt.title('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32cbbbb7-2d10-4fab-9c46-e9fb93295e58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdis\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dis' is not defined"
     ]
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d452968-4c31-4c95-be1a-09aefadaa55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
