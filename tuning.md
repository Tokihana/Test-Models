# 项目开始前的准备

## batch size

通常情况下，更换架构就意味着更换batchsize，所以每个架构都需要做一次batchsize测试。

由于大多数超参都是batch size敏感的，更改batchsize，通常意味着改变大部分超参。

与batch size关联最明显的超参是optimizer（例如lr，sgd的momentum）与正则化参数，因此每次更改batch size，都需要重新调整这些参数。

所以，对每个架构，最好一开始就定下来batch size，否则后面会很麻烦。



### 最大可承受batchsize

以2的幂次为步进，测试硬件最高能够承受的batchsize范围

### throughput

> 做throughput的目的是检查是否存在训练流程上的瓶颈，例如I/O或者多卡并行的同步点。

$$
throughput = (examples\ per\ second) = \frac {(num\ of\ examples)} {(time)}\\
(time\ per\ step/batch) = \frac {(batch\ size)}{throughput}
$$

On RTX4060Ti（**IR50**）

| batch size | throughput<br />(example per second) | time per step<br />(time per batch) |
| ---------- | ------------------------------------ | ----------------------------------- |
| 1          | 92                                   | 0.01                                |
| 2          | 145                                  | 0.01                                |
| 4          | 164                                  | 0.02                                |
| 8          | 150                                  | 0.05                                |
| 16         | 161                                  | 0.10                                |
| 32         | 156                                  | 0.20                                |
| 64         | 157                                  | 0.41                                |

On RTX3090（**IR50**)

| batch size | throughput<br />(example per second) | time per step<br />(time per batch) |
| ---------- | ------------------------------------ | ----------------------------------- |
| 1          | 151                                  | 0.007                               |
| 2          | 318                                  | 0.006                               |
| 4          | 346                                  | 0.012                               |
| 8          | 364                                  | 0.022                               |
| 16         | 414                                  | 0.039                               |
| 32         | 447                                  | 0.071                               |
| 64         | 450                                  | 0.142                               |
| 128        | 458                                  | 0.279                               |
| 256        | 465                                  | 0.550                               |
| 512        | 464                                  | 1.101                               |
| 1024       | 显存满了                             |                                     |

很有意思的现象，显存虽然没满，但throughput明显偏向饱和了。

且time per step在很小的batch之后，就开始翻倍，大概是开始排队了。

这应该也就代表，hardware saturated不代表显存满了，只是核全被用上了。显存可能更多与图像的大小有关。

尝试将图像大小压小一些（224 -> 112），看看是不是可以跑1024的batch size

| batch size | throughput | time per step |
| ---------- | ---------- | ------------- |
| 1          | 161        | 0.006         |
| 2          | 310        | 0.006         |
| 4          | 610        | 0.007         |
| 8          | 1231       | 0.006         |
| 16         | 1471       | 0.011         |
| 32         | 1546       | 0.021         |
| 64         | 1662       | 0.038         |
| 128        | 1777       | 0.072         |
| 256        | 1812       | 0.141         |
| 512        | 1826       | 0.280         |
| 1024       | 1835       | 0.558         |

确实可以跑，这样一看，如果图像尺寸不是大的非常离谱，显存通常都是有富余的。

总结一下：

- 显存占用量通常与data scale的关联更大，更大的图像、更大的中间张量对显存的占用更加明显
- throughput对应着硬件本身的计算速度，在运算单元全部被占用（saturated）之前，增加batch_size，等价于增加还未被使用的运算单元，此时batch_size加倍，对应throughput加倍，time_per_step不变。这个效应通常会在batch_size增加到一定程度后饱和，变为batch_size加倍、time_per_step加倍（开始排队），throughput可能会继续增加，但逐渐接近某个上限。
- 如果throughput已经到达了增长的上限，此时继续加大batchsize并不会带来运行效率上的提升，就没必要再加了

### 通过throughput评估训练时间，选择最快的batchsize

$$
training\ time = (time\ per\ step) * (num\ steps)
$$

- 训练时间最短的batch size，就是在throughput到达临界值前，仍能够提升throughput的最大batch size
- 一般来说，受制于硬件条件，throughput可能不会到达临界值，所以惯例上会选择能够使用的最大batch size



## 初始参数配置

初始参数配置通常包括：

1. 模型参数，例如layer num
2. optimizer参数，例如lr
3. 训练轮数

寻找调参前的初始配置通常需要经过几次手动配置，为尽可能简化这一过程，在进行初始配置时，应注意：

- 可以先不采用一些额外的操作，例如weight decay，先用恒定lr进行训练
- 采用开销最小的配置进行试验，例如使用最小的模型
- 这一过程获得的性能指标通常不会太好
- 选择较少的训练次数，因为LR会受到训练轮数的影响，最开始的epoch调太高的话，后面可能就没法调整epoch了。



# 模型微调策略

在开始之前，确保已经满足：

- 模型的训练已经跑通，且已经调好相对可以接受的初始参数
- 有足够的训练资源，最好可以并行跑微调

整体的策略，遵循增量调整：

1. 从简单配置开始，逐步添加功能；并在每个功能都使用自动搜索算法
2. 每次更新到更好的配置时，确保有据可循，而不是碰运气去找合适的配置



## 深入理解问题

调参的重心不仅仅是提高验证集上的表现，更进一步是用于深入了解问题，从而：

- 辨别那些因为此前的改动、而不是本轮的调参而产生的良好效果
- 判断验证结果对哪些超参最敏感，这些超参需要每次都调整；哪些超参相关性不高，可以在后续实验中采用固定值。
- 寻找潜在的优化方向
- 去除无效的方向
- 判断调参的优化空间是否已经饱和
- 收缩搜索范围



## 选择目标

每轮试验都应有明确的目标，解决一个足够小的问题，例如：

- 改进训练流程，增加预处理方法
- 了解特定超参的影响
- 最大化验证指标



## 设计下一轮试验

根据目标，将超参进行分类：

- 目标超参：对模型产生影响的超参
- 冗余超参：必须共同优化，才能够公平比较不同超参的参数
- 固定参数：不需要改变的参数

举例来说，研究目标是：**更深的模型是否能够加点**，那么：

- 目标超参是模型深度
- LR是冗余超参，对不同深度的模型，需要分别调整学习率
- 激活函数可能是固定超参，也可能是冗余超参，可通过试验验证。

在设计新一轮实验室，遵循以下步骤：

1. 根据目标设定目标超参，首先将所有的其他参数都是为冗余超参。
2. 将一部分冗余超参转为固定超参，这部分参数的影响通常不大；不过要谨慎选择，因为如果被固定的参数与目标参数相关性很高，那么很可能得不到任何实验结果。

一些经验法则：

- optimizer的参数通常存在一些冗余参数；但很少是目标超参，因为像LR这种参数很容易随着训练流程、模型架构等发生变化。
  - 虽然有时可能会固定一些optimizer的参数，但通常应该单独调整
- 选择哪个optimizer通常是目标超参或者固定超参
- 正则的参数通常是冗余参数，但是否使用正则一般是目标或者固定参数
  - 例如，是否使用dropout通常会被配置为一个目标参数，而drop_ratio通常是冗余参数
- 模型结构通常是目标或固定超参
- 对optimizer这种，通常会引入不同的新冗余参数的情况，将被引入的新参数称为**条件超参数**



